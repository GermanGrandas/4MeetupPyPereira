{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector\n",
    "\n",
    "*Dataset from https://www.kaggle.com/karthickveerakumar/spam-filter/data * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "INITIAL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('emails.csv')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "def getCorpus(data):\n",
    "    ps = PorterStemmer()\n",
    "    corpus = []\n",
    "    for review in data:\n",
    "        x = re.sub('[^a-zA-Z]',' ',review).lower().split()\n",
    "        corpus.append(' '.join([ps.stem(word) for word in x if not word in set(stopwords.words('english'))]))\n",
    "    return corpus\n",
    "\n",
    "def getWordBag(data):    \n",
    "    corpus = getCorpus(data)\n",
    "    maxF = 2000\n",
    "    cv = CountVectorizer(max_features=maxF)\n",
    "    X = cv.fit_transform(corpus).toarray()\n",
    "    \n",
    "    global INITIAL\n",
    "    if np.all(INITIAL ==None):\n",
    "         INITIAL = corpus\n",
    "            \n",
    "    if X.shape[1] < maxF:\n",
    "        y=cv.fit_transform(INITIAL).toarray()\n",
    "        aux  = [[0]*y.shape[1]]\n",
    "        w = cv.get_feature_names()\n",
    "        for word in corpus:\n",
    "            for y in word.split():\n",
    "                if y in w:\n",
    "                    pos = w.index(y)\n",
    "                    aux[0][pos] = 1\n",
    "        X = np.array(aux)\n",
    "    return X\n",
    "\n",
    "def liked(review):\n",
    "    if review == [False]:\n",
    "        return \"No es spam.\"\n",
    "    else:\n",
    "        return \"Es Spam, Tener cuidado.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el tiempo fue: 10.887896386782328 minutos\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "        \n",
    "t0 = time()\n",
    "X = getWordBag(dataset['text'])\n",
    "t1 = time()\n",
    "print(\"el tiempo fue: {} minutos\".format((t1-t0)/60))\n",
    "y = dataset['spam']\n",
    "X_train , X_test, y_train, y_test = train_test_split(X,y,test_size= 0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4296/4296 [==============================] - 32s 7ms/step - loss: 0.1589 - acc: 0.9574\n",
      "Epoch 2/10\n",
      "4296/4296 [==============================] - 30s 7ms/step - loss: 0.0558 - acc: 0.9907\n",
      "Epoch 3/10\n",
      "4296/4296 [==============================] - 30s 7ms/step - loss: 0.0587 - acc: 0.9935\n",
      "Epoch 4/10\n",
      "4296/4296 [==============================] - 30s 7ms/step - loss: 0.0397 - acc: 0.9953\n",
      "Epoch 5/10\n",
      "4296/4296 [==============================] - 30s 7ms/step - loss: 0.0397 - acc: 0.9963\n",
      "Epoch 6/10\n",
      "4296/4296 [==============================] - 30s 7ms/step - loss: 0.0366 - acc: 0.9967\n",
      "Epoch 7/10\n",
      "4296/4296 [==============================] - 29s 7ms/step - loss: 0.0179 - acc: 0.9981\n",
      "Epoch 8/10\n",
      "4296/4296 [==============================] - 30s 7ms/step - loss: 0.0240 - acc: 0.9972\n",
      "Epoch 9/10\n",
      "4296/4296 [==============================] - 30s 7ms/step - loss: 0.0194 - acc: 0.9984\n",
      "Epoch 10/10\n",
      "4296/4296 [==============================] - 30s 7ms/step - loss: 0.0156 - acc: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209422b7d68>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ann = Sequential()\n",
    "shape = int(X.shape[1]/2)\n",
    "Ann.add(Dense(units=shape,kernel_initializer='uniform',activation='relu',input_dim=X.shape[1]))\n",
    "Ann.add(Dropout(0.7))\n",
    "Ann.add(Dense(units=shape,kernel_initializer='uniform',activation='relu'))\n",
    "Ann.add(Dropout(0.7))\n",
    "Ann.add(Dense(units=1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "        \n",
    "Ann.compile(optimizer='RMSprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "Ann.fit(X_train,y_train,batch_size=10,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1081    8]\n",
      " [  10  333]]\n",
      "98.74301675977654\n"
     ]
    }
   ],
   "source": [
    "y_pred = Ann.predict(X_test)\n",
    "y_pred = (y_pred>0.5)\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "accuracy = ((cm[0][0]+cm[1][1])/X_test.shape[0])*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es Spam, Tener cuidado.\n",
      "No es spam.\n"
     ]
    }
   ],
   "source": [
    "pred = '''Subject: 10 minutes before sex , lasts for 24 - 36 hours  legal , \n",
    "            prescription medications under the essential guidance of licensed medical  under every stone lurks a politician .  \n",
    "            experience is the name everyone gives to their mistakes .  without music , life would be a mistake .\"'''\n",
    "\n",
    "X1 = getWordBag([pred])\n",
    "y1 = Ann.predict(X1) > 0.5\n",
    "print(liked(y1))\n",
    "\n",
    "\n",
    "pred = '''Subject: presentation for cal berkeley  hello vince and john ,  i wanted to forward to you both the current presentations for campus . we can  tweak these however we feel appropriate to match cal berkeley on monday . \n",
    "        i  believe that we can probably expect about 30 - 50 students ( based on interest  shown at the career fair ) . these tend to be fairly informal . \n",
    "        i was thinking  that we could present in this order :  vince gives the enron overview presentation ( 30 minutes )  john gives the global technology specific presentation ( 20 minutes )  ashley goes over recruiting information at the end ( 10 minutes )  please take a look at each presentation and speaker notes to ensure that you  feel comfortable with the layout and content . \n",
    "        i am meeting with john today  at 1 : 30 - vince if you would like to get together and discuss as well that  would be great .  \n",
    "        if you have any questions , please don ' t hesitate to contact me . 3 - 3589  thanks ,  ashley  vince , here is a copy of the current enron overview presentation . \n",
    "        there are  also speaker notes that go into great detail .  john , here is a copy of the current technology presentation for carnegie  mellon . the only changes will be to the recruiting dates at the end . \n",
    "        there  are also speaker notes that go into greater detail . - - - >'''\n",
    "X1 = getWordBag([pred])\n",
    "y1 = Ann.predict(X1) > 0.5\n",
    "print(liked(y1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
